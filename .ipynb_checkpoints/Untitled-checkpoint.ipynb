{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Important imports\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob as glb\n",
    "\n",
    "\n",
    "Current_fit_Left = []\n",
    "Current_fit_Right = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Camera Calibration and undistortion function\n",
    "\n",
    "def Camera_Calibration(img, nx, ny, objp, img_points, obj_points):\n",
    "    # Read the undistorted image \n",
    "    dist_image = mpimg.imread(img)\n",
    "    # Covert the undistorted image into grayscale\n",
    "    gray = cv2.cvtColor(dist_image, cv2.COLOR_RGB2GRAY)\n",
    "    # find the corners in the chessboard if found\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    \n",
    "    if ret == True:\n",
    "        img_points.append(corners)\n",
    "        obj_points.append(objp)\n",
    "        # draw chessboad corners over the original image\n",
    "        cv2.drawChessboardCorners(dist_image, (nx,ny), corners, ret)\n",
    "        # calibrate the camera that takes these chessboard images\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, gray.shape[::-1], None, None)\n",
    "        # undistort the input image\n",
    "        undist_image = cv2.undistort(dist_image, mtx, dist, None, mtx)\n",
    "    \n",
    "    if ret == False:\n",
    "        # return the same imput of obj_points and img_points \n",
    "        return None,None,obj_points, img_points,None,None\n",
    "    \n",
    "    return dist_image, undist_image, obj_points, img_points, mtx, dist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prespective transform\n",
    "\n",
    "def corners_unwrap(img, nx, ny, mtx, dist, Src_points, Dest_points, read=True):\n",
    "    # Corners are the region of intrest whicg is the trapozoidal points\n",
    "    # mtx, dist are calculated from the calibration process donr over the chessboard\n",
    "    \n",
    "    if read == True:\n",
    "        # read the img by cv2.imraed\n",
    "        dist_img = mpimg.imread(img)\n",
    "        # undistort the input image\n",
    "        undist_image = cv2.undistort(dist_img, mtx, dist, None, mtx)\n",
    "        # convert to grascale\n",
    "        gray = cv2.cvtColor(undist_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    elif read == False:\n",
    "        # undistort the input image\n",
    "        #undist_image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        gray = img\n",
    "    \n",
    "    # define the image size from the grayscale converted image\n",
    "    image_size = (gray.shape[1], gray.shape[0])\n",
    "    # Calculate src, dst points to calculate the prespective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(Src_points, Dest_points)\n",
    "    # wrap the image\n",
    "    #warped = cv2.warpPerspective(undist_image, M, image_size, flags=cv2.INTER_LINEAR)\n",
    "    warped = cv2.warpPerspective(gray, M, image_size, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "    return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Camera Calibration\n",
    "\n",
    "# pickle to save both mtx, and dist out of the camera calibration\n",
    "dict_pickle = {}\n",
    "\n",
    "# Read from the Chessboard images we have\n",
    "n_rows = 9 # rows corners in the chessboard\n",
    "n_cols = 6 # columns corners in the chessboard\n",
    "\n",
    "# Define initialization for 2D and 3D points\n",
    "obj_points = [] # 3D points in real world space \n",
    "img_points = [] # 2D points in image plane\n",
    "\n",
    "# Define Initialization for Images Read\n",
    "Distorted_images = []   # to save the original images after imread()\n",
    "Undistorted_images = [] # to save the undistorted images out from cv2\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), ....... (8,5,0)\n",
    "objp = np.zeros((n_rows*n_cols,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:n_rows, 0:n_cols].T.reshape(-1,2)\n",
    "\n",
    "# Read images from camera_cal folder \n",
    "fname = glb.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "\n",
    "for image in fname:\n",
    "    distorted_image, undistorted_image, obj_points, img_points, C_matrix, dist_factor = Camera_Calibration(image, n_rows, n_cols, objp, img_points, obj_points)\n",
    "    \n",
    "    Distorted_images.append(distorted_image)\n",
    "    Undistorted_images.append(undistorted_image)\n",
    "\n",
    "dict_pickle[\"mtx\"]  = C_matrix\n",
    "dict_pickle[\"dist\"] = dist_factor\n",
    "\n",
    "pickle.dump(dict_pickle, open(\"camera_calibrate.p\", 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check saving parameters in pickle\n",
    "pickle_load = pickle.load(open(\"camera_calibrate.p\", 'rb'))\n",
    "\n",
    "print(pickle_load[\"mtx\"])\n",
    "print(pickle_load[\"dist\"])\n",
    "\n",
    "# Now we can use these parameters for any images needed to be calibrated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the prespective trabsformation using image (calibration12.jpg)\n",
    "test_image = \"camera_cal/calibration12.jpg\"\n",
    "test_image_read = cv2.imread(test_image)\n",
    "test_gray = cv2.cvtColor(test_image_read, cv2.COLOR_BGR2GRAY)\n",
    "test_ret, test_corners = cv2.findChessboardCorners(test_gray, (n_rows,n_cols), None)\n",
    "\n",
    "\n",
    "# image size\n",
    "image_size = (test_gray.shape[1], test_gray.shape[0])\n",
    "# offset for dst points\n",
    "offset = 100 \n",
    "# source needed for the presepective transform\n",
    "src = np.float32([test_corners[0], test_corners[n_rows-1], test_corners[-1], test_corners[-n_rows]])\n",
    "# destination needed for the prespective transform\n",
    "dest = np.float32([[offset, offset], [image_size[0]-offset, offset], \n",
    "                  [image_size[0]-offset, image_size[1]-offset],\n",
    "                  [offset, image_size[1]-offset]])\n",
    "\n",
    "test_top_down, test_prespective_M = corners_unwrap(test_image, n_rows, n_cols, dict_pickle[\"mtx\"], dict_pickle[\"dist\"], src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_image_read)\n",
    "plt.show()\n",
    "plt.imshow(test_top_down)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Combination between Gradient and Color thresholging methods\n",
    "\n",
    "# In this part, we will test using (test images) folder for the road in order to\n",
    "# have a good way of comparison with the output generated in the lectures\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Gradient thresold functions\n",
    "\n",
    "# Absolute sobel threshold\n",
    "def abs_sobel_thresh(img, orient, sobel_kernel, thresh):\n",
    "    # Notes: \n",
    "    # 1) sobel_kernel must be odd\n",
    "    # 2) thresh is a tuble (thresh_min = , thresh_max = )\n",
    "    \n",
    "    # This image must be read by cv2\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if orient == \"x\":\n",
    "        # calculate sobelx\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    elif orient == \"y\":\n",
    "        # calculate sobely\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # take the absolute value of the derivative\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # Scale to 8-bit (0-255) then cast to be np.uint8\n",
    "    Scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a mask of 1's where the scaled gradient magnitude \n",
    "    # is greater than threshold min and less than the threshold max\n",
    "    binary_output = np.zeros_like(Scaled_sobel)\n",
    "    binary_output[(Scaled_sobel >= thresh[0]) & (Scaled_sobel < thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Magnitude threshold\n",
    "def mag_thresh(img, sobel_kernel, mag_thresh):\n",
    "    # It will be implemented as the previous, but calculating sobel from the magnitude of both x and y\n",
    "    # Notes: \n",
    "    # 1) sobel_kernel must be odd\n",
    "    # 2) mag_thresh is a tuble (mag_thresh_min = , mag_thresh_max = )\n",
    "    \n",
    "    # This image must be read by cv2\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate sobel x and y then calculate their magnitude\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Scale to 8-bit (0-255) and cast to be uint8 \n",
    "    Scaled_sobel = (255*mag_sobel/np.max(mag_sobel)).astype('uint8')\n",
    "    # Create the mask using the boundary thresolds\n",
    "    binary_output = np.zeros_like(Scaled_sobel)\n",
    "    binary_output[(Scaled_sobel >= mag_thresh[0]) & (Scaled_sobel < mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Direction of the gradient threshold\n",
    "def dir_thresh(img, sobel_kernel, dir_thresh):\n",
    "    # It will be implemented as the previous, but calculating sobel angle (gradient) using arctan2 \n",
    "    # Notes:\n",
    "    # 1) sobel_kernel must be odd\n",
    "    # 2) dir_thresh is a tuble (dir_thresh_min = , dir_thresh_max = )\n",
    "    \n",
    "    # This image must be read by cv2\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculate sobel x and y then calculate their magnitude\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # calculate the absolute value of both of sobelx, and sobely\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    # calculate the gradient using the arctan2 to put threshold\n",
    "    dir_grad = np.arctan2(abs_sobely,abs_sobelx)\n",
    "    # Create the mask using the boundary thresolds\n",
    "    binary_output = np.zeros_like(dir_grad)\n",
    "    binary_output[(dir_grad >= dir_thresh[0]) & (dir_grad < dir_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color thresold functions\n",
    "\n",
    "def hls_select(img, hls_thresh):\n",
    "    # Notes:\n",
    "    # 1) hls_thresh is a tuble (hls_thresh_min = , hls_thresh_max = )\n",
    "    \n",
    "    # This image must be read by cv2\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    # apply thresholding to have the S-channel only from the HLS components\n",
    "    S_Channel = hls[:,:,1] \n",
    "    # Create the mask using the boundaries\n",
    "    binary_output = np.zeros_like(S_Channel)\n",
    "    binary_output[(S_Channel >= hls_thresh[0]) & (S_Channel <= hls_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Binary thresold in order to make the shadow unseen\n",
    "def LAB_select(img, LAB_thresh):\n",
    "    LAB = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    B_Channel = LAB[:,:,2]\n",
    "    # Create the mask using the boundaries\n",
    "    binary_output = np.zeros_like(B_Channel)\n",
    "    binary_output[(B_Channel >= LAB_thresh[0]) & (B_Channel <= LAB_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "def hsv_select(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    yellow_mask = cv2.inRange(hsv, np.array((0,100,100)), np.array((80,255,255)))\n",
    "    white_mask = cv2.inRange(img, np.array((200,200,200)), np.array((255,255,255)))\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    binary_output = np.zeros_like(mask)\n",
    "    binary_output[(mask == 255)] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline of thresolding based on both \n",
    "# Gradient and color thresholding\n",
    "\n",
    "def Pipline_threshold(image):\n",
    "    Absolute_thresholding_x         = abs_sobel_thresh(image, orient = \"x\", sobel_kernel = 9, thresh = (40,100) )\n",
    "    Absolute_thresholding_y         = abs_sobel_thresh(image, orient = \"y\", sobel_kernel = 9, thresh = (80,180) )\n",
    "    Magnitude_thresholding          = mag_thresh(image, sobel_kernel = 9, mag_thresh = (50,150) )\n",
    "    Gradient_Direction_thresholding = dir_thresh(image, sobel_kernel = 9, dir_thresh = (0,np.pi/2) )\n",
    "    HLS_thresholding                = hls_select(image, hls_thresh = (255,255))\n",
    "    LAB_thresholding                = LAB_select(image, LAB_thresh=(40,100))\n",
    "    HSV_thresholding                = hsv_select(image)\n",
    "    \n",
    "    Combined_binary = np.zeros_like(Absolute_thresholding_x)\n",
    "    '''\n",
    "    (Absolute_thresholding_x == 1) |\n",
    "    (LAB_thresholding == 1) |\n",
    "    ((HLS_thresholding == 1) & (Gradient_Direction_thresholding == 1))\n",
    "    '''\n",
    "    Combined_binary[(HSV_thresholding == 1) |\n",
    "                   (Absolute_thresholding_x == 1)\n",
    "                   ] = 1\n",
    "    \n",
    "    color_binary = np.dstack((np.zeros_like(Absolute_thresholding_x), Absolute_thresholding_x, HLS_thresholding)) * 255\n",
    "    \n",
    "    return Combined_binary, color_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_pipeline = \"test_images/test1.jpg\"\n",
    "Read_test_image_pipeline = mpimg.imread(test_image_pipeline)\n",
    "\n",
    "output_combined_binaries, coloring_binary = Pipline_threshold(Read_test_image_pipeline)\n",
    "\n",
    "plt.imshow(Read_test_image_pipeline)\n",
    "plt.show()\n",
    "plt.imshow(output_combined_binaries, cmap=\"gray\")\n",
    "plt.show()\n",
    "plt.imshow(coloring_binary, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prespective Transform Check on these images in order to have Bird's view for the street\n",
    "Source_road_points = np.float32([[575,460], [150,720], [1150,720], [700,460]])\n",
    "Destination_road_points = np.float32([[250,0], [250,720], [1050,720], [1050,0]])\n",
    "\n",
    "Source_road_points = np.float32([[575,460], [150,720], [1150,720], [700,460]])\n",
    "Destination_road_points = np.float32([[250,0], [250,720], [1050,720], [1050,0]])\n",
    "\n",
    "\n",
    "test_top_down_road, test_road_prespective_M = corners_unwrap(test_image_pipeline, \n",
    "                                                             n_rows, n_cols, dict_pickle[\"mtx\"],dict_pickle[\"dist\"], \n",
    "                                                             Source_road_points, Destination_road_points, True)\n",
    "\n",
    "#plt.imshow(test_top_down_road, cmap=\"gray\")\n",
    "#plt.show()\n",
    "\n",
    "test_top_down_road, test_road_prespective_M = corners_unwrap(output_combined_binaries, \n",
    "                                                             n_rows, n_cols, dict_pickle[\"mtx\"],dict_pickle[\"dist\"], \n",
    "                                                             Source_road_points, Destination_road_points, False)\n",
    "\n",
    "plt.imshow(test_top_down_road, cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we have done the following steps:\n",
    "    1- Camera Calibration\n",
    "    2- Image Distortion Correction\n",
    "    3- Gradient and Color thresholding\n",
    "    4- Prespective transform to have a Bird's eye images\n",
    "    \n",
    "Now we want to do the following steps:\n",
    "    1- Locate the Lanes lines using the code in the lectures (Using the Histogram method of the two peaks)\n",
    "    2- Using the sliding window in order to know the full Lane Lines in the image\n",
    "    3- Fitting a polynomial for the Lane using the codes in the lectures\n",
    "    4- Measuring the Curvature (Remember: within approx. 1k.m)\n",
    "    \n",
    "For the Full Pipeline:\n",
    "    1- Work on the video to extract the images frame by frame (Not Yet)\n",
    "    2- Image Distortion and Correction (Done)\n",
    "    3- Gradient and Color thresholding (DOne)\n",
    "    4- Prespective transform to have the Bird's eye images that facilitate \n",
    "    extracting the Lanes Lines and fit a polynomial (Done)\n",
    "    5- Extract Lanes Lines using the Histogram method (Not Yet)\n",
    "    6- Apply Sliding window to locate the whole lines (Not Yet)\n",
    "    7- Fitting a polynomial for the whole lane lines (Not Yet)\n",
    "    8- Measure the Lanes Curvature (Not Yet)\n",
    "    9- Save the video (Not Yet)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the histogram of the output image\n",
    "\n",
    "def Calculate_histogram(image, plotting=False):\n",
    "    histogram = np.sum(image[image.shape[0]//2:,:], axis=0)\n",
    "    if plotting == True:\n",
    "        plt.plot(histogram,\"b\")\n",
    "        plt.show()\n",
    "    \n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the Histogram function\n",
    "Calculate_histogram(test_top_down_road, plotting=True)\n",
    "\n",
    "# Thios means that the two lanes lines are located at the two peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Finding the Lanes Lines and Fit a polynomial \n",
    "def PolynomialFit_LanesLines(image):\n",
    "    # The input image should be the Bird's eye image\n",
    "    \n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 13\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 70\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "        \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = Calculate_histogram(image, plotting=False)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((image, image, image))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(image.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = image.shape[0] - (window+1)*window_height\n",
    "        win_y_high = image.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "                      (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "                      (win_xright_high,win_y_high),(0,255,0), 2)\n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        \n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    print(leftx)\n",
    "    print(lefty)\n",
    "    print(rightx)\n",
    "    print(righty)\n",
    "    \n",
    "    global Current_fit_Left\n",
    "    global Current_fit_Right\n",
    "    \n",
    "    print(Current_fit_Left, Current_fit_Right)\n",
    "    \n",
    "    \n",
    "    # Sanity Check if the lanes are detected or not\n",
    "    if (len(leftx) == 0):\n",
    "        print(\"Lanes are not detected\")\n",
    "        # Call the function that draws lines without using sliding window\n",
    "        left_fit, right_fit, out_img, leftx, lefty, rightx, righty = Skip_SlidingWindow_Visualization(out_img, Current_fit_Left, Current_fit_Right)\n",
    "        \n",
    "    else:\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "    Current_fit_Left = left_fit\n",
    "    Current_fit_Right = right_fit\n",
    "    \n",
    "    print(Current_fit_Left, Current_fit_Right)\n",
    "    \n",
    "    return left_fit, right_fit, out_img, leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PolynomialFit_Visulaization(image):\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "    \n",
    "    left_fit, right_fit, output_image, L_x, L_y, R_x, R_y = PolynomialFit_LanesLines(image)\n",
    "    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    #output_image[L_y, L_x] = [255, 0, 0]\n",
    "    #output_image[R_y, R_x] = [0, 0, 255]\n",
    "    \n",
    "    #plt.imshow(output_image)\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    #plt.show()\n",
    "    \n",
    "    return left_fitx, right_fitx, left_fit, right_fit, L_x, L_y, R_x, R_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeftFitX, RightFitX, LeftFit, RightFit, Left_X, Left_Y, Right_X, Right_Y = PolynomialFit_Visulaization(test_top_down_road)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skipping Function for the sliding window technique. \n",
    "# This Function could be used when we know the positions of the Lanes Lines\n",
    "\n",
    "def Skip_SlidingWindow(image, left_fit, right_fit):\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 70\n",
    "    \n",
    "    # Create an image to draw on \n",
    "    #output_image = np.dstack((image, image, image))*255\n",
    "    \n",
    "    nonzero = image.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    print(\"Here: \", left_fit)\n",
    "    print(\"Here: \", right_fit)\n",
    "    \n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit_poly = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit_poly = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    return left_fit_poly, right_fit_poly, image, leftx, lefty, rightx, righty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize fitting without Sliding window\n",
    "\n",
    "def Skip_SlidingWindow_Visualization(image, left_fit, right_fit):\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 70\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0])\n",
    "    LFit, RFit, output_image, Lx, Ly, Rx, Ry = Skip_SlidingWindow(image, left_fit, right_fit) \n",
    "    \n",
    "    left_fitx = LFit[0]*ploty**2 + LFit[1]*ploty + LFit[2]\n",
    "    right_fitx = RFit[0]*ploty**2 + RFit[1]*ploty + RFit[2]\n",
    "    \n",
    "    # Create an image to show the selection window\n",
    "    #window_img = np.zeros_like(output_image)\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    #output_image[Ly, Lx] = [255, 0, 0]\n",
    "    #output_image[Ry, Rx] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    #left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    #left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "    #left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    \n",
    "    #right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    #right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "    #right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    #cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    #cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    #result = cv2.addWeighted(output_image, 1, window_img, 0.3, 0)\n",
    "    #plt.imshow(result)\n",
    "    #plt.plot(left_fitx, ploty, color='yellow')\n",
    "    #plt.plot(right_fitx, ploty, color='yellow')\n",
    "    #plt.show()\n",
    "    \n",
    "    return LFit, RFit, output_image, Lx, Ly, Rx, Ry\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualization for Skipping Window technique\n",
    "Skip_SlidingWindow_Visualization(test_top_down_road, LeftFit, RightFit)\n",
    "\n",
    "# Here I have used the same output of the same image in order to check the functionality of Skipping Sliding window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring the Curvature Function in pixels\n",
    "\n",
    "def Curvature_Measurement_pix(image, left_fit, right_fit, leftx, lefty, rightx, righty):\n",
    "    left_curverad = ((1 + (2*left_fit[0]*np.max(lefty) + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*np.max(righty) + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "    #print(left_curverad, \"in pixels\", right_curverad, \"in pixels\")\n",
    "    \n",
    "    \n",
    "# Test the Radius of Curvature\n",
    "Curvature_Measurement_pix(test_top_down_road, LeftFit, RightFit, Left_X, Left_Y, Right_X, Right_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring the Curvature Function in meters\n",
    "\n",
    "def Curvature_Measurement_m(image, left_fit, right_fit, leftx, lefty, rightx, righty):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad  = ((1 + (2*left_fit_cr[0]*np.max(lefty) + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*np.max(righty) + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "    \n",
    "# Test the Radius of Curvature\n",
    "Curvature_Measurement_m(test_top_down_road, LeftFit, RightFit, Left_X, Left_Y, Right_X, Right_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reverse Projection for the image and fill between the two polylines for the lanes\n",
    "def Reverse_and_Fill(original_image, warped_image, left_fitx, right_fitx, Minv):\n",
    "    warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    ploty = np.linspace(0, warped_image.shape[0]-1, warped_image.shape[0])\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (original_image.shape[1], original_image.shape[0]))\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(original_image, 1, newwarp, 0.3, 0)\n",
    "    #plt.imshow(result)\n",
    "    #plt.show()\n",
    "    \n",
    "    return result\n",
    "    \n",
    "Reverse_and_Fill(Read_test_image_pipeline, test_top_down_road, LeftFitX, RightFitX, np.linalg.inv(test_road_prespective_M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Function writes on the image some measurements\n",
    "\n",
    "def Write_Measurements(image, Radius_curve, leftfitx, rightfitx):\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    Veh_position = image.shape[1]//2\n",
    "    middle = (leftfitx[-1] + rightfitx[-1])//2\n",
    "    dx = (Veh_position - middle) * xm_per_pix # Positive if on right, Negative on left\n",
    "    \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(image,'Left radius of curvature  = %.2f m'%(Radius_curve[0]),(50,50), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(image,'Right radius of curvature = %.2f m'%(Radius_curve[1]),(50,80), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(image,'Vehicle position : %.2f m %s of center'%(abs(dx), 'left' if dx < 0 else 'right'),(50,110), font, 1,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Now we want to apply all of the previous steps over the images extracted from the project video frame by frame.\n",
    "But first we need to construct the Full Pipeline in One function in order facilitate tracing the code\n",
    "\n",
    "We will follow the following steps:\n",
    "    1- We have calibrated the camera, so we will use its parameters (Done)\n",
    "    2- Image Distortion correction (Done)\n",
    "    3- Apply Gradient and Color thresholding (Done)\n",
    "    4- Apply prespective transform till have the Bird's eye view (Done)\n",
    "    5- Polynomial Fitting (Done)\n",
    "    6- Calculate both (Radius of Curvature and the Car's Position away from the 2 lane lines) (Not Yet Totally)\n",
    "    7- Reverse and Fill between the two Line Lanes (Done)\n",
    "    8- Write Left and Right Radius on the image in addition to the Car's position\n",
    "    \n",
    "Important Note: The image is already read, so every read using mpimg or cv2 will be commented\n",
    "'''\n",
    "\n",
    "def Advanced_Lane_Finding(image):\n",
    "    # Read from the Chessboard images we have\n",
    "    n_rows = 9 # rows corners in the chessboard\n",
    "    n_cols = 6 # columns corners in the chessboard\n",
    "    \n",
    "    #Src_road_pts = np.float32([[575,460], [150,720], [1150,720], [700,460]])\n",
    "    #Dest_road_pts = np.float32([[320,0], [320,720], [950,720], [950,0]])\n",
    "    \n",
    "    Src_road_pts = np.float32([[575,460], [150,720], [1150,720], [700,460]])\n",
    "    Dest_road_pts = np.float32([[250,0], [250,720], [1050,720], [1050,0]])\n",
    "    \n",
    "    \n",
    "    #Destination_road_points = np.float32([[250,0], [250,720], [1050,720], [1050,0]])\n",
    "    \n",
    "    # 1- Load the saved pickle that contains the Camera Calibration parameters\n",
    "    Cal_Params = pickle.load(open(\"camera_calibrate.p\", 'rb'))\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 2- Use the Calibration parameters to undistort the input image\n",
    "    undist_image = cv2.undistort(image, Cal_Params[\"mtx\"], Cal_Params[\"dist\"], None, Cal_Params[\"mtx\"])\n",
    "    #plt.imshow(undist_image)\n",
    "    #plt.show()\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 3- Apply Gradient and Color thresholding\n",
    "    image_binaries, image_color_binary = Pipline_threshold(undist_image)\n",
    "    #plt.imshow(image_binaries, cmap=\"gray\")\n",
    "    #plt.show()\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 4- Apply prespective transform\n",
    "    image_warped, image_M = corners_unwrap(image_binaries, n_rows, n_cols, \n",
    "                                                  Cal_Params[\"mtx\"],Cal_Params[\"dist\"], \n",
    "                                                  Src_road_pts, Dest_road_pts, False)\n",
    "    #plt.imshow(image_warped, cmap=\"gray\")\n",
    "    #plt.show()\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 5- Polynomial Fitting and draw rectangles in green with the pplynomial lines in yellow with Visualization\n",
    "    LFitX, RFitX, LFit, RFit, LX, LY, RX, RY = PolynomialFit_Visulaization(image_warped)\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 6- Calculate Radius Curvature\n",
    "    R_curve_pix = Curvature_Measurement_pix(image_warped, LFit, RFit, LX, LY, RX, RY)\n",
    "    R_curve_met = Curvature_Measurement_m(image_warped, LFit, RFit, LX, LY, RX, RY)\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 7- Reverse and Fill between the two lines\n",
    "    image_output = Reverse_and_Fill(image, image_warped, LFitX, RFitX, np.linalg.inv(image_M))\n",
    "    \n",
    "    ##################################################################################################\n",
    "    \n",
    "    # 8- Write Measurements on the video's image\n",
    "    image_output_with_measurements = Write_Measurements(image_output, R_curve_met, LFitX, RFitX)\n",
    "    #plt.imshow(image_output_with_measurements)\n",
    "    #plt.show()\n",
    "\n",
    "    return image_output_with_measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Test_images_Folder = \"test_images/*.jpg\"\n",
    "All_File = glb.glob(Test_images_Folder)\n",
    "\n",
    "print(All_File)\n",
    "\n",
    "for im in All_File:\n",
    "    print(im[12:])\n",
    "    Im_Read = mpimg.imread(im)\n",
    "    Advanced_Lane_Finding(Im_Read)\n",
    "    print(\"###########################################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import imageio\n",
    "imageio.plugins.ffmpeg.download()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# project_output_video = \"project_output_video.mp4\"\n",
    "# clip = VideoFileClip(\"project_video.mp4\")\n",
    "# output_video = clip.fl_image(Advanced_Lane_Finding) #  .subclip(0,35)   NOTE: this function expects color images!!\n",
    "# %time output_video.write_videofile(project_output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project_output_video = \"challenge_output_video.mp4\"\n",
    "clip = VideoFileClip(\"challenge_video.mp4\")\n",
    "output_video = clip.fl_image(Advanced_Lane_Finding)# NOTE: this function expects color images!!\n",
    "%time output_video.write_videofile(project_output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_output_video = \"harder_challenge_output_video.mp4\"\n",
    "# clip = VideoFileClip(\"harder_challenge_video.mp4\")\n",
    "# output_video = clip.fl_image(Advanced_Lane_Finding) #NOTE: this function expects color images!!\n",
    "# %time output_video.write_videofile(project_output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
